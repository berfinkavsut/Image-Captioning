{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().system('pip install \"git+https://github.com/salaniz/pycocoevalcap.git\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from struct import unpack\n",
    "\n",
    "import h5py\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow_addons.rnn import LayerNormLSTMCell\n",
    "from tensorflow_addons.rnn import LayerNormSimpleRNNCell\n",
    "\n",
    "import keras\n",
    "from keras.layers.merge import add\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Lambda, Input, LSTM, GRU, RNN, Embedding, Multiply,  Concatenate, TimeDistributed, Dense, Bidirectional, RepeatVector, Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization\n",
    "\n",
    "TRAIN_DATA_FILENAME = \"../input/project-data/eee443_project_dataset_train.h5\"\n",
    "TRAIN_IMAGES_DIRECTORY = \"../input/images-for-train/train_images/\"\n",
    "TRAIN_FEATURES_DIRECTORY = \"../input/tupled-data/train_tupled_data\"\n",
    "\n",
    "TEST_DATA_FILENAME = \"../input/project-data/eee443_project_dataset_test.h5\"\n",
    "TEST_IMAGES_DIRECTORY = \"../input/images-for-test/test_images/\"\n",
    "TEST_FEATURES_DIRECTORY = \"../input/tupled-data/test_tupled_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ims(data, pathname):\n",
    "    \"\"\"\n",
    "    A function which saves images from given urls\n",
    "    :param data: the array which holds url values\n",
    "    :param pathname: the save path\n",
    "    \"\"\"\n",
    "    s = time.time()\n",
    "    i = 0\n",
    "\n",
    "    if not os.path.exists(pathname):\n",
    "        os.makedirs(pathname)\n",
    "\n",
    "    for url in data:\n",
    "\n",
    "        url = url.decode()\n",
    "        name = url.split(\"/\")[-1].strip()\n",
    "        path = os.path.join(pathname, name)\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "\n",
    "            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36'}\n",
    "            response = requests.get(url, stream=True, headers=headers)\n",
    "\n",
    "            # check if data is obttained successfully\n",
    "            if response.status_code == 200:\n",
    "                    with open(path, 'wb') as outfile:\n",
    "                        outfile.write(response.content)\n",
    "\n",
    "        # prints affirmation at each 1000 iterations\n",
    "        if i % 1000 == 1:\n",
    "\n",
    "            p = time.time() - s\n",
    "            it = p/i\n",
    "            print(\"{:.2f} mins passed. {:.2f} seconds per iter. Iteration {}\".format(p/60, it, i))\n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JPEG:\n",
    "    \"\"\"\n",
    "    The JPEG class which helps in cleaning the data, more info can be found on the report.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_file):\n",
    "        with open(image_file, 'rb') as f:\n",
    "            self.img_data = f.read()\n",
    "\n",
    "    def decode(self):\n",
    "        data = self.img_data\n",
    "        while (True):\n",
    "            marker, = unpack(\">H\", data[0:2])\n",
    "            # print(marker_mapping.get(marker))\n",
    "            if marker == 0xffd8:\n",
    "                data = data[2:]\n",
    "            elif marker == 0xffd9:\n",
    "                return\n",
    "            elif marker == 0xffda:\n",
    "                data = data[-2:]\n",
    "            else:\n",
    "                lenchunk, = unpack(\">H\", data[2:4])\n",
    "                data = data[2 + lenchunk:]\n",
    "            if len(data) == 0:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_bad_JPEG(root_img):\n",
    "    \"\"\"\n",
    "    A funciton which clears a directory from bad JPEG's (.jpg files that are not actually images)\n",
    "    :param root_img: tthe directory of jpg images\n",
    "    \"\"\"\n",
    "\n",
    "    images = os.listdir(root_img)\n",
    "\n",
    "    bads = []\n",
    "\n",
    "    for img in tqdm(images):\n",
    "        image = root_img + img\n",
    "        image = JPEG(image)\n",
    "        try:\n",
    "            image.decode()\n",
    "        except:\n",
    "            bads.append(img)\n",
    "    print(bads)\n",
    "    for name in bads:\n",
    "        os.remove(root_img + name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption_array_to_str(caption_array):\n",
    "    \"\"\"\n",
    "    A function which formats a caption numpy array to a list of string(s). Used for evaluation and prediction.\n",
    "    :param caption_array: The numpy array which stores captions/predicted captions\n",
    "    :return: a list of strings that contain the caption\n",
    "    \"\"\"\n",
    "    \n",
    "    list_of_captions = []\n",
    "\n",
    "    caption = \"\"\n",
    "\n",
    "    if(caption_array.ndim == 1):\n",
    "        caption_array = np.expand_dims(caption_array, axis=0)\n",
    "\n",
    "    for caps in caption_array:\n",
    "\n",
    "        for word in caps:\n",
    "\n",
    "            if (word == 'x_NULL_') or (word == 'x_START_') or (word == 'x_END_'):\n",
    "                continue\n",
    "                \n",
    "            caption += word + \" \"\n",
    "            \n",
    "            \n",
    "        list_of_captions.append(caption.strip())\n",
    "        caption = \"\"\n",
    "\n",
    "        \n",
    "    return list_of_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_caption(name_list, imid, cap, name):\n",
    "    \"\"\"\n",
    "    A function which returns the caption of an image given its name\n",
    "    :param name_list:\n",
    "    :param imid: image id vector\n",
    "    :param cap: cap array (holds all captions)\n",
    "    :param name: the name of the image\n",
    "    :return: the caption numpy array\n",
    "    \"\"\"\n",
    "  \n",
    "    ind = name_list.index(name) + imid.min()\n",
    "  \n",
    "    return cap[np.where(imid == ind)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pre_processed_set(image_directory, shuffle=False):\n",
    "    \"\"\"\n",
    "    A function which creates a set of preprocessed images ready for feature extraction.\n",
    "    :param image_directory: The directory containing all images\n",
    "    :param shuffle: whetther we want to shuffle data or not\n",
    "    :return: a tf.data.Dataset that contains all preprocessed images (contains meaning it contains the formula to create them,\n",
    "    however the data is not actual loaded into memory until called)\n",
    "    \"\"\"\n",
    "\n",
    "    def process_files(path):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, (299, 299))\n",
    "        img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "        return img\n",
    "\n",
    "    def process_name(path):\n",
    "        name = path.numpy().decode().split(\"/\")[-1]\n",
    "        return name\n",
    "\n",
    "    def process(path):\n",
    "        name = tf.py_function(process_name, [path], tf.string)\n",
    "        img = tf.py_function(process_files, [path], tf.float32)\n",
    "        return (img, name)\n",
    "    \n",
    "    file_data = tf.data.Dataset.list_files(str(image_directory) + \"*.jpg\", shuffle=shuffle)\n",
    "    \n",
    "    return file_data.map(lambda x: process(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(filename, images, name_list, imid, cap, process_size = 250):\n",
    "    \"\"\"\n",
    "\n",
    "    :param filename: the filename for the data to be dumped in\n",
    "    :param images: the image tf.data.Dataset (created in the previous function)\n",
    "    :param name_list: a list of image url names\n",
    "    :param imid: image id array\n",
    "    :param cap: captions array\n",
    "    :param process_size: the batch size with which the feattures are extracted\n",
    "    :return: the length of the data\n",
    "    \"\"\"\n",
    "\n",
    "    inception = tf.keras.applications.InceptionV3(weights='imagenet')\n",
    "    inception = tf.keras.Model(inception.input, inception.layers[-2].output)\n",
    "    \n",
    "    \n",
    "    length = 0\n",
    "    \n",
    "    with open(filename, \"wb\") as outfile:\n",
    "        \n",
    "        for data in tqdm(images.batch(process_size)):\n",
    "                \n",
    "            image = data[0]\n",
    "            name = data[1].numpy()\n",
    "            feature = inception(image).numpy()\n",
    "            \n",
    "            for i in range(feature.shape[0]):\n",
    "                \n",
    "                f = feature[i].squeeze()\n",
    "                n = name[i].decode()\n",
    "                c = get_caption(name_list, imid, cap, n)\n",
    "                \n",
    "                tp = (f, c, n)\n",
    "                pickle.dump(tp, outfile)\n",
    "                \n",
    "                length += 1\n",
    "\n",
    "    outfile.close()\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadpickle(filename):\n",
    "    \"\"\"\n",
    "    A generator function which yields data in a file until there is none\n",
    "    :param filename:\n",
    "    :return: loaded tuple (or any other data that is stored)\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filename, \"rb\") as f:\n",
    "        while True:\n",
    "\n",
    "            try:\n",
    "                yield pickle.load(f)\n",
    "\n",
    "            except EOFError:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(feature_directory, url=None, imid=None, cap=None, image_directory=None):\n",
    "    \"\"\"\n",
    "\n",
    "    :param feature_directory: directory of the pickled data\n",
    "    :param url: url array (from the given dataset)\n",
    "    :param imid: image id vector (from the given dataset)\n",
    "    :param cap: cap array (from the given dataset)\n",
    "    :param image_directory: the directory images are stored in\n",
    "    :return: the dataset and the length of said dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    length = -1\n",
    "    \n",
    "    if not os.path.isfile(feature_directory):\n",
    "        \n",
    "        if not image_directory:\n",
    "            raise Exception(\"No image directory given. Enter image directory for feature extraction.\")\n",
    "        \n",
    "        name_list = [u.split(\"/\")[-1].strip() for u in np.char.decode(url).tolist()]\n",
    "        images = create_pre_processed_set(image_directory)\n",
    "        length = create_features(feature_directory, images, name_list, imid, cap)\n",
    "        \n",
    "    dataset = tf.data.Dataset.from_generator(loadpickle, args=[feature_directory], output_types=(np.float32,np.int32, tf.string))\n",
    "\n",
    "    if length == -1:\n",
    "        length = dataset.reduce(0, lambda x, _: x + 1).numpy()\n",
    "    \n",
    "    return dataset, length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Train Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(TRAIN_DATA_FILENAME, \"r\")\n",
    "\n",
    "for key in list(f.keys()):\n",
    "    print(key, \":\", f[key][()].shape)\n",
    "\n",
    "train_cap = f[\"train_cap\"][()]\n",
    "train_imid = f[\"train_imid\"][()]\n",
    "train_url = f[\"train_url\"][()]\n",
    "word_code = f[\"word_code\"][()]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(word_code)\n",
    "df = df.sort_values(0, axis=1)\n",
    "words = np.asarray(df.columns)\n",
    "\n",
    "wordtoix = {}\n",
    "for i in range(len(words)):\n",
    "  word = words[i]\n",
    "  wordtoix[word] = i\n",
    "\n",
    "\n",
    "train_data, train_data_length = create_data( TRAIN_FEATURES_DIRECTORY, train_url, train_imid, train_cap, TRAIN_IMAGES_DIRECTORY)\n",
    "\n",
    "print(\"Vocab Size =\", len(words))\n",
    "print( \"{} of {} retrieved. {:.1f}% of data is clean.\".format(train_data_length, len(train_url), 100 * train_data_length/len(train_url) ) )\n",
    "\n",
    "# delete after use so that memory is not loaded\n",
    "del train_cap \n",
    "del train_imid\n",
    "del train_url \n",
    "del word_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in train_data.shuffle(1000).take(1):\n",
    "    features = d[0]\n",
    "    image_name= d[2].numpy().decode()\n",
    "    captions = d[1].numpy()\n",
    "    \n",
    "    \n",
    "    im = cv2.imread(TRAIN_IMAGES_DIRECTORY + image_name)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "    cap = caption_array_to_str(words[captions])\n",
    "\n",
    "    for c in cap:\n",
    "        print(c)\n",
    "        \n",
    "    print(features.shape, captions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Test Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(TEST_DATA_FILENAME, \"r\")\n",
    "\n",
    "for key in list(f.keys()):\n",
    "    print(key, \":\", f[key][()].shape)\n",
    "\n",
    "test_cap = f[\"test_caps\"][()]\n",
    "test_imid = f[\"test_imid\"][()]\n",
    "test_url = f[\"test_url\"][()]\n",
    "\n",
    "test_data, test_data_length = create_data(TEST_FEATURES_DIRECTORY, test_url, test_imid, test_cap, TEST_IMAGES_DIRECTORY)\n",
    "\n",
    "print( \"{} of {} retrieved. {:.1f}% of data is clean.\".format(test_data_length, len(test_url), 100 * test_data_length/len(test_url) ))\n",
    "\n",
    "# delete after use so that memory is not loaded\n",
    "del test_cap \n",
    "del test_imid\n",
    "del test_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in test_data.shuffle(1000).take(1):\n",
    "    features = d[0]\n",
    "    captions = d[1].numpy()\n",
    "    image_name= d[2].numpy().decode()\n",
    "    \n",
    "    im = cv2.imread(TEST_IMAGES_DIRECTORY + image_name)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "    cap = caption_array_to_str(words[captions])\n",
    "    \n",
    "    for c in cap:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(dataset, max_length, num_photos_per_batch, vocab_size):\n",
    "    \"\"\"\n",
    "    The data generatoor function which generates training data\n",
    "    :param dataset: the tf.data.Dataset object containing tthe tuple (feature, captions, name)\n",
    "    :param max_length: maximum sentence/caption length in terms of words\n",
    "    :param num_photos_per_batch: batch size\n",
    "    :param vocab_size: vocabulary size, word count\n",
    "    :return: the training data to be used at every iteration\n",
    "    \"\"\"\n",
    "\n",
    "    X1, X2, y = [], [], []\n",
    "    i = 0\n",
    "\n",
    "    while True:\n",
    "\n",
    "        for data in dataset:\n",
    "\n",
    "            i += 1\n",
    "            feature = data[0].numpy()\n",
    "            caps = data[1].numpy()\n",
    "\n",
    "            for j in range(caps.shape[0]):\n",
    "\n",
    "                seq = caps[j]\n",
    "\n",
    "                for k in range(1, seq.shape[0]):\n",
    "\n",
    "                    in_seq = pad_sequences([seq[:k]], maxlen=max_length)[0]\n",
    "                    out_seq = to_categorical([seq[k]], num_classes=vocab_size)[0]\n",
    "\n",
    "                    X1.append(feature)\n",
    "                    X2.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "\n",
    "\n",
    "            if i == num_photos_per_batch:\n",
    "\n",
    "                yield [np.array(X1), np.array(X2)], np.array(y)\n",
    "                X1, X2, y = [], [], []\n",
    "                i = 0\n",
    "\n",
    "    yield [np.array(X1), np.array(X2)], np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding(wordtoix):\n",
    "    \"\"\"\n",
    "    Mehod which creates the embedding matrix wih a given word index dictionary\n",
    "    :param wordtoix: word intex\n",
    "    :return: the embedding matrtix\n",
    "    \"\"\"\n",
    "    # Load Glove vectors\n",
    "    glove_dir = '../input/glove6b200d/glove.6B.200d.txt'\n",
    "    embeddings_index = {} # empty dictionary\n",
    "    f = open(glove_dir, encoding=\"utf-8\")\n",
    "\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        # if (word == 'startseq' or word == 'unk' ):\n",
    "        #   print(word)\n",
    "\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "    embedding_dim = 200\n",
    "    vocab_size = 1004\n",
    "\n",
    "    # Get 200-dim dense vector for each of the 10000 words in out vocabulary\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    for word, i in wordtoix.items():\n",
    "\n",
    "        if (word == 'x_UNK_'):\n",
    "          word = 'unk'\n",
    "\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if  embedding_vector is None:\n",
    "          print(word)\n",
    "\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in the embedding index will be all zeros\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st Iteration Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_merge_model(embedding_matrix):\n",
    "    \n",
    "    inputs1 = Input(shape=(2048,))\n",
    "    img1 = Dropout(0.5)(inputs1)\n",
    "    img2 = Dense(256, activation='relu')(img1)\n",
    "    \n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    seq1 = Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs2)\n",
    "    seq2 = Dropout(0.5)(seq1)\n",
    "    seq3 = LSTM(256)(seq2)\n",
    "    \n",
    "    #add, not concatenate! wrong \n",
    "    dec1 = add([img1, seq3])\n",
    "    dec2 = Dense(256, activation='relu')(dec1)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(dec2)\n",
    "    \n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "    \n",
    "    #set embedding layer's weight matrix \n",
    "    model.layers[2].set_weights([embedding_matrix])\n",
    "    model.layers[2].trainable = True\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_init_inject_model(embedding_matrix):\n",
    "    \n",
    "    inputs1 = Input(shape=(2048,))\n",
    "    img1 = Dropout(0.5)(inputs1)\n",
    "    img2 = Dense(256, activation='relu')(img1)\n",
    "    \n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    seq1 = Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs2)\n",
    "    seq2 = Dropout(0.5)(seq1)\n",
    "\n",
    "    #image is set as state \n",
    "    seq3,state = GRU(256,return_state = True)(seq2,initial_state = img1)\n",
    "    \n",
    "    dec2 = Dense(256, activation='relu')(seq3)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(dec2)\n",
    "    \n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)    \n",
    "    \n",
    "    #set embedding layer's weight matrix \n",
    "    model.layers[2].set_weights([embedding_matrix])\n",
    "    model.layers[2].trainable = True\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_pre_inject_model(embedding_matrix):\n",
    "    \n",
    "    inputs1 = Input(shape=(2048,))\n",
    "    img1 = Dropout(0.5)(inputs1)\n",
    "    img2 = Dense(embedding_dim, activation='relu')(img1)\n",
    "    img2_reshaped = Reshape((1, embedding_dim), input_shape=(embedding_dim,))(img2)\n",
    "\n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    seq1 = Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs2)\n",
    "    seq2 = Dropout(0.5)(seq1)\n",
    "    seq3,state3 = GRU(256,return_state = True)(img2_reshaped)\n",
    "    seq4,state4 = GRU(256,return_state = True)(seq2, initial_state = state3)\n",
    "    dec = Dense(256, activation='relu')(seq4)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(dec)\n",
    "\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)    \n",
    "\n",
    "    model.layers[4].set_weights([embedding_matrix])\n",
    "    model.layers[4].trainable = True\n",
    "   \n",
    "        \n",
    "    return model\n",
    "\n",
    "def create_par_inject_model(embedding_matrix):\n",
    "    \n",
    "    max_length = 17\n",
    "    vocab_size = 1004\n",
    "    embedding_dim = 200\n",
    "    \n",
    "    inputs1 = Input(shape=(2048,))\n",
    "    img1 = Dropout(0.5)(inputs1)\n",
    "    img2 = Dense(200, activation='relu')(img1)\n",
    "\n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    seq1 = Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs2)\n",
    "    seq2 = Dropout(0.5)(seq1)\n",
    "\n",
    "    mul = Multiply()([img2,seq2])\n",
    "\n",
    "    seq3 = LSTM(256)(mul)\n",
    "    dec = Dense(256, activation='relu')(seq3)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(dec)\n",
    "\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "\n",
    "    model.layers[3].set_weights([embedding_matrix])\n",
    "    model.layers[3].trainable = True\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models with Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_merge_model_best(embedding_matrix):\n",
    "\n",
    "    inputs1 = Input(shape=(2048,))\n",
    "    img = Dense(128, activation='relu', kernel_initializer='random_normal')(inputs1)\n",
    "\n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    seq1 = Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs2)\n",
    "\n",
    "    seq2 = RNN(LayerNormLSTMCell(128))(seq1)\n",
    "    seq3 = Dropout(0.5)(seq2)\n",
    "\n",
    "    dec1 = add([img, seq3])\n",
    "    dec2 = Dense(128, activation='relu',kernel_initializer='random_normal')(dec1)\n",
    "    outputs = Dense(vocab_size, activation='softmax',kernel_initializer='random_normal')(dec2)\n",
    "\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "\n",
    "    #set embedding layer's weight matrix \n",
    "    model.layers[1].set_weights([embedding_matrix])\n",
    "    model.layers[1].trainable = True\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_par_inject_model_best(embedding_matrix):\n",
    "\n",
    "    inputs1 = Input(shape=(2048,))\n",
    "    img1 = Dropout(0.5)(inputs1)\n",
    "    img2 = Dense(200, activation='relu',kernel_initializer='random_normal',kernel_regularizer=tf.keras.regularizers.l2(1e-8))(img1)\n",
    "\n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    seq1 = Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs2)\n",
    "    seq2 = Dropout(0.5)(seq1)\n",
    "\n",
    "    mul = Multiply()([img1,seq2])\n",
    "\n",
    "    seq3 = RNN(LayerNormLSTMCell(256))(mul)\n",
    "    seq4 = Dropout(0.5)(seq3)\n",
    "    dec = Dense(256, activation='relu',kernel_initializer='random_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-8))(seq4)\n",
    "    outputs = Dense(vocab_size, activation='softmax',kernel_initializer='random_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-8))(dec)\n",
    "\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "    \n",
    "    model.layers[3].set_weights([embedding_matrix])\n",
    "    model.layers[3].trainable = True\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_pre_inject_model_best(embedding_matrix):\n",
    "\n",
    "    inputs1 = Input(shape=(2048,))\n",
    "    img = Dense(embedding_dim, activation='relu',kernel_initializer='random_normal')(inputs1)\n",
    "    img_reshaped = Reshape((1, embedding_dim), input_shape=(embedding_dim,))(img)\n",
    "\n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    seq1 = Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs2)\n",
    "    seq2 = Dropout(0.5)(seq1)\n",
    "\n",
    "\n",
    "    seq3,state3 = RNN(LayerNormSimpleRNNCell(512),return_state = True)(img_reshaped)\n",
    "    seq4,state4 = RNN(LayerNormSimpleRNNCell(512),return_state = True)(seq2, initial_state = state3)\n",
    "\n",
    "    seq5 = Dropout(0.5)(seq4)\n",
    "    dec = Dense(512, activation='relu',kernel_initializer='random_normal')(seq5)\n",
    "    outputs = Dense(vocab_size, activation='softmax',kernel_initializer='random_normal')(dec)\n",
    "\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "\n",
    "    model.layers[3].set_weights([embedding_matrix])\n",
    "    model.layers[3].trainable = True\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_init_inject_model_best(embedding_matrix):\n",
    "\n",
    "    inputs1 = Input(shape=(2048,))\n",
    "\n",
    "    img = Dense(512, activation='relu')(inputs1)\n",
    "\n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    seq1 = Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs2)\n",
    "    seq2 = Dropout(0.5)(seq1)\n",
    "\n",
    "    #image is set as state \n",
    "    seq3,state = RNN(LayerNormSimpleRNNCell(512),return_state = True)(seq2,initial_state = img)\n",
    "    seq4 = Dropout(0.5)(seq3)\n",
    "\n",
    "    dec = Dense(512, activation='relu')(seq4)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(dec)\n",
    "\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "\n",
    "\n",
    "    #set embedding layer's weight matrix \n",
    "    model.layers[1].set_weights([embedding_matrix])\n",
    "    model.layers[1].trainable = True\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-Directional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bilstm_model_layernorm(embedding_matrix):\n",
    "\n",
    "    inputs1 = Input(shape=(2048,))\n",
    "    img1 = Dense(embedding_dim, input_shape=(2048,), activation='relu')(inputs1)\n",
    "    img2 = RepeatVector(max_length)(img1)\n",
    "     \n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    seq1 = Embedding(vocab_size,embedding_dim, input_length=max_length, mask_zero=True)(inputs2)\n",
    "    seq2 = Bidirectional(RNN(LayerNormLSTMCell(256), return_sequences = True))(seq1)\n",
    "    seq3 = Dropout(0.5)(seq2)\n",
    "    seq4 = TimeDistributed(Dense(embedding_dim))(seq3)\n",
    "\n",
    "    comb1 = Concatenate(axis=2)([img2, seq4])\n",
    "    comb2 = Dropout(0.5)(comb1)\n",
    "    comb3 = Bidirectional(RNN(LayerNormLSTMCell(1000), return_sequences = False))(comb2)\n",
    "    comb4 = Dense(vocab_size, activation = 'softmax')(comb3)\n",
    "        \n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=comb4)\n",
    "    model.summary()\n",
    "    \n",
    "    model.layers[1].set_weights([embedding_matrix])\n",
    "    model.layers[1].trainable = True\n",
    "      \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train \n",
    "Note: Skip to load pre-existing models\n",
    "\n",
    "### Creating the Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating embedding matrix...\")\n",
    "embedding_matrix = create_embedding(wordtoix)\n",
    "print('Embedding matrix is ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = 10000 #train_datta_length\n",
    "train_data = train_data.take(data_length)\n",
    "\n",
    "val_length = round(data_length * 0.15)\n",
    "train_length = data_length - val_length\n",
    "\n",
    "val_dataset = train_data.take(val_length) \n",
    "train_dataset = train_data.skip(val_length)\n",
    "\n",
    "max_length = 17\n",
    "vocab_size = 1004\n",
    "embedding_dim = 200\n",
    "\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = False\n",
    "\n",
    "if train_ == True: \n",
    "    model_names = [\"create_merge_model_best\", \n",
    "                   \"create_par_inject_model_best\", \n",
    "                   \"create_pre_inject_model_best\", \n",
    "                   \"create_init_inject_model_best\"]\n",
    "\n",
    "    history_list = {}\n",
    "\n",
    "    for i in range(2, 3):\n",
    "\n",
    "        if i == 0:\n",
    "            model = create_merge_model_best(embedding_matrix) \n",
    "            batch_size = 128\n",
    "        if i == 1:\n",
    "            model = create_par_inject_model_best(embedding_matrix) \n",
    "            batch_size = 64\n",
    "        if i == 2:\n",
    "            model = create_pre_inject_model_best(embedding_matrix) \n",
    "            batch_size = 32\n",
    "        if i == 3:\n",
    "            model = create_init_inject_model_best(embedding_matrix) \n",
    "            batch_size = 128\n",
    "\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "        print(\"Model compiled...\")\n",
    "\n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(model_names[i], monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "        callbacks_list = [checkpoint]\n",
    "\n",
    "        print(\"Creating Generators\")\n",
    "        train_generator = data_generator(train_dataset, max_length, batch_size, vocab_size)\n",
    "        val_generator = data_generator(val_dataset, max_length, batch_size, vocab_size)\n",
    "\n",
    "        train_step = train_length // batch_size\n",
    "        val_step = val_length // batch_size\n",
    "\n",
    "\n",
    "        print(\"Starting training...\")\n",
    "        start = time.time()\n",
    "\n",
    "        history = model.fit(train_generator,\n",
    "                        steps_per_epoch = train_step,\n",
    "                        validation_data = val_generator,\n",
    "                        validation_steps = val_step,\n",
    "                        epochs = epochs,\n",
    "                        callbacks = callbacks_list,\n",
    "                            workers = 0)\n",
    "\n",
    "        history_list[model_names[i]] = history.history\n",
    "\n",
    "\n",
    "        model.save(model_names[i] + \"_save\")\n",
    "\n",
    "\n",
    "        print(\"Time spent {:.2f} mins.\".format( (time.time()-start)/60 ))\n",
    "\n",
    "\n",
    "    with open('loss_history.json', 'w') as fp:\n",
    "        json.dump(history_list, fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-Saved Models and History Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "path = \"../input/models/old_models/old_models/\"\n",
    "\n",
    "with open(path + 'old_loss_history.json', 'r') as fp:\n",
    "    history_dict = json.load(fp)\n",
    "    \n",
    "with open(\"../input/models/bidirectional/loss_history_alt_batchnorm.json\", 'r') as fp:\n",
    "    bihist = json.load(fp)\n",
    "    \n",
    "\n",
    "for key in history_dict:\n",
    "    try:\n",
    "        models[key] = tf.keras.models.load_model(path + key, custom_objects={'LayerNormLSTMCell':LayerNormLSTMCell})\n",
    "    except:\n",
    "        try:\n",
    "            models[key] = tf.keras.models.load_model(path + key, custom_objects={'LayerNormSimpleRNNCell':LayerNormSimpleRNNCell})\n",
    "        except:\n",
    "            print(\"Could not load model.\")\n",
    "            \n",
    "            \n",
    "try:\n",
    "    bi = tf.keras.models.load_model(\"../input/models/bidirectional/create_bilstm_model_layernorm_batchnorm\", custom_objects={'LayerNormLSTMCell':LayerNormLSTMCell})\n",
    "except:\n",
    "    try:\n",
    "        bi= tf.keras.models.load_model(\"../input/models/bidirectional/create_bilstm_model_layernorm_batchnorm\", custom_objects={'LayerNormSimpleRNNCell':LayerNormSimpleRNNCell})\n",
    "    except:\n",
    "        print(\"Could not load model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot History (Different Blocks for the Report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(model_name, hist):\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 8), dpi=160, facecolor='w', edgecolor='k')\n",
    "    fig.suptitle(model_name, fontsize=13)\n",
    "    plt.plot(hist[\"loss\"], \"C2\", label=\"Train Sequential Cross Entropy Loss\")\n",
    "    plt.plot(hist[\"val_loss\"], \"C3\", label=\"Validation Sequential Cross Entropy Loss\")\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.savefig(\"pre_inject.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 4), dpi=160, facecolor='w', edgecolor='k')\n",
    "c = [\"C2\", \"C3\"]\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "h1 = list(history_dict.values())[4]\n",
    "h2 = list(bihist.values())[0]\n",
    "\n",
    "plt.plot(h1[\"loss\"], c[0], label=\"Modified Merge Model\")\n",
    "plt.plot(h2[\"loss\"], c[1], label=\"Bi-Directional Model\")\n",
    "\n",
    "plt.title(\"Train Loss\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')   \n",
    "plt.legend() \n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "plt.plot(h1[\"val_loss\"], c[0], label=\"Modified Merge Model\")\n",
    "plt.plot(h2[\"val_loss\"], c[1], label=\"Bi-Directional Model\")\n",
    "\n",
    "plt.title(\"Validation Loss\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')   \n",
    "plt.legend()  \n",
    "plt.savefig(\"Loss_Plots_BiDir_Merge.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 4), dpi=160, facecolor='w', edgecolor='k')\n",
    "\n",
    "c = [\"C1\", \"C2\", \"C3\", \"C4\"]\n",
    "names = [\"Merge Model\", \"Par Inject Model\", \"Pre Inject Model\", \"Init Inject Model\"]\n",
    "# names = [\"Modified Merge Model\", \"Modified Par Inject Model\",\n",
    "#              \"Modified Pre Inject Model\", \"Modified Init Inject Model\"]\n",
    "h = list(history_dict.values())[4:]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4), dpi=160, facecolor='w', edgecolor='k')\n",
    "plt.subplot(1,2,1)\n",
    "for i in range(4):\n",
    "    plt.plot(h[i][\"loss\"], c[i], label=names[i])\n",
    "plt.title('Training Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')   \n",
    "plt.legend()    \n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "for i in range(4):\n",
    "    plt.plot(h[i][\"val_loss\"], c[i], label=names[i])\n",
    "plt.title('Validation Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')   \n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"Loss_Plots.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 12), dpi=160, facecolor='w', edgecolor='k')\n",
    "c = [\"C2\", \"C3\"]\n",
    "names = [\"Merge Model\", \"Par Inject Model\", \"Pre Inject Model\", \"Init Inject Model\",\n",
    "            \"Modified Merge Model\", \"Modified Par Inject Model\",\n",
    "             \"Modified Pre Inject Model\", \"Modified Init Inject Model\"]\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i + 1)\n",
    "    h1 = list(history_dict.values())[i]\n",
    "    h2 = list(history_dict.values())[i + 4]\n",
    "\n",
    "    plt.plot(h1[\"loss\"], c[0], label=names[i])\n",
    "    plt.plot(h2[\"loss\"], c[1], label=names[i + 4])\n",
    "    \n",
    "    \n",
    "    plt.title('Train Loss for ' + names[i] + \"s\")\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')   \n",
    "    plt.legend()  \n",
    "    \n",
    "plt.savefig(\"Loss_Plots_Comparison_Modified.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_evaluation_dictionary(model, dataset, data_length, batch_size, words):\n",
    "    \"\"\"\n",
    "    Creates a dictionary for the score listing function\n",
    "    :param model: the model the predictions will be based on\n",
    "    :param dataset: the tf.data.Dataset object, in our case this is the test dataset\n",
    "    :param data_length: the data length of the dataset\n",
    "    :param batch_size: this is the process size, how many predictions are to be done at once\n",
    "    :param words: the words dictionary\n",
    "    :return:\n",
    "    \"\"\"\n",
    "        \n",
    "    pred_container = {}\n",
    "    actual_container = {}\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    referenced = dataset.map(lambda x, y, z: (x, z))\n",
    "    \n",
    "    for batch in referenced.batch(batch_size):\n",
    "        \n",
    "        feats = batch[0].numpy()\n",
    "        iteration = feats.shape[0]\n",
    "        seq = np.tile(np.array([1] + [0]*16), (iteration, 1))\n",
    "        \n",
    "        for i in range(16):\n",
    "\n",
    "            pred = model.predict([feats, seq])\n",
    "            seq[:, i+1] = np.argmax(pred, axis=1)\n",
    "            \n",
    "        for i in range(iteration):\n",
    "            \n",
    "            name = batch[1].numpy()[i].decode()\n",
    "            pred_container[name] = caption_array_to_str(words[seq[i]])\n",
    "\n",
    "    for d in dataset.take(data_length):\n",
    "        name = d[2].numpy().decode()\n",
    "        caption = d[1].numpy()\n",
    "        actual_container[name] = caption_array_to_str(words[caption])\n",
    "\n",
    "        \n",
    "    return actual_container, pred_container  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocoevalcap.bleu.bleu import Bleu\n",
    "from pycocoevalcap.rouge.rouge import Rouge\n",
    "from pycocoevalcap.cider.cider import Cider \n",
    "from pycocoevalcap.meteor.meteor import Meteor\n",
    "\n",
    "def score(ref, hypo):\n",
    "    \"\"\"\n",
    "    ref, dictionary of reference sentences (id, sentence)\n",
    "    hypo, dictionary of hypothesis sentences (id, sentence)\n",
    "    score, dictionary of scores\n",
    "    \"\"\"\n",
    "    scorers = [(Bleu(4), [\"Bleu_1\", \"Bleu_2\", \"Bleu_3\", \"Bleu_4\"]),\n",
    "                (Meteor(),\"METEOR\"),\n",
    "                (Rouge(), \"ROUGE_L\"),\n",
    "                (Cider(), \"CIDEr\")]\n",
    "    \n",
    "    final_scores = {}\n",
    "    \n",
    "    for scorer, method in scorers:\n",
    "        \n",
    "        score, scores = scorer.compute_score(ref, hypo)\n",
    "        \n",
    "        if type(score) == list:\n",
    "            \n",
    "            for m, s in zip(method, score):\n",
    "                \n",
    "                final_scores[m] = s\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            final_scores[method] = score\n",
    "            \n",
    "            \n",
    "    return final_scores \n",
    "\n",
    "def print_metrics(actual, preds, model_name):\n",
    "    \n",
    "    metric_dict = score(actual, preds)\n",
    "    \n",
    "    b1 = metric_dict[\"Bleu_1\"] * 100\n",
    "    b2 = metric_dict[\"Bleu_2\"] * 100\n",
    "    b3 = metric_dict[\"Bleu_3\"] * 100\n",
    "    b4 = metric_dict[\"Bleu_4\"] * 100\n",
    "    m = metric_dict[\"METEOR\"] * 100\n",
    "    r = metric_dict[\"ROUGE_L\"] * 100\n",
    "    c = metric_dict[\"CIDEr\"] * 100\n",
    "    string = \"\\n--------------------\\nModel: {}\\n--------------------\\nBLEU-1: {:.1f}\\nBLEU-2: {:.1f}\\nBLEU-3: {:.1f}\\nBLEU-4: {:.1f}\\nMETEOR:  {:.1f}\\nROGUE_L: {:.1f}\\nCIDEr: {:.1f}\\n\".format(model_name, b1, b2, b3, b4, m, r, c)\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Bleu, Meteor, CIDEr and Rouge_L Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Example of a score output (this might take a short while)...\\n\")\n",
    "data_size = test_data_length\n",
    "process_size = 250\n",
    "prediction_data = test_data.take(data_size)\n",
    "\n",
    "actual, preds = create_evaluation_dictionary(models[\"create_pre_inject_model_best\"], prediction_data, data_size, process_size, words)\n",
    "print_metrics(actual, preds, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Predicted Image with Caption (for the report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_extra(model, feature_model, img_path):\n",
    "    \"\"\"\n",
    "    prediction function for extra images, not provided to us via test dataset\n",
    "    this is for fun but also to see if the model can actually correctly guess any other image (spoiler: it can)\n",
    "    :param model: the prediction model\n",
    "    :param feature_model: feature extraction model\n",
    "    :param img_path: path of image to be predicted\n",
    "    \"\"\"\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (299, 299))\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = feature_model(img)\n",
    "    img = img.numpy().reshape(1, -1)\n",
    "\n",
    "    seq = np.array([0]*17).reshape(1, -1)\n",
    "\n",
    "    seq[:, 0] = 1\n",
    "\n",
    "    for i in range(16):\n",
    "        pred = model.predict([img,seq])\n",
    "        seq[:, i+1] = np.argmax(pred)\n",
    "\n",
    "    seq = seq.reshape(-1)\n",
    "\n",
    "    im = cv2.imread(img_path)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    fig = plt.figure(dpi=160, facecolor='w', edgecolor='k')\n",
    "    plt.imshow(im)\n",
    "    plt.title(\"Prediction: \" + caption_array_to_str(words[seq])[0], fontsize=9)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_caption(model, image_directory, feature_model, amount, dr):\n",
    "    \"\"\"\n",
    "    A function which predicts and saves many caption/prediction duos plotted with their respective images\n",
    "    :param model: prediction model\n",
    "    :param image_directory: the image directory, test images directory\n",
    "    :param feature_model: feature extraction model\n",
    "    :param amount: how many pictures the function will be predicting\n",
    "    :param dr: the save directory\n",
    "    \"\"\"\n",
    "    \n",
    "    for d in test_data.shuffle(test_data_length).take(amount):\n",
    "    \n",
    "        img_path = str(image_directory + d[2].numpy().decode())\n",
    "        c = d[1].numpy()\n",
    "        k = np.random.randint(c.shape[0])\n",
    "    \n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, (299, 299))\n",
    "        img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = feature_model(img)\n",
    "        img = img.numpy().reshape(1, -1)\n",
    "\n",
    "        seq = np.array([0]*17).reshape(1, -1)\n",
    "\n",
    "        seq[:, 0] = 1\n",
    "\n",
    "        for i in range(16):\n",
    "            pred = model.predict([img,seq])\n",
    "            seq[:, i+1] = np.argmax(pred)\n",
    "\n",
    "        seq = seq.reshape(-1)\n",
    "\n",
    "        im = cv2.imread(img_path)\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        fig = plt.figure(dpi=160, facecolor='w', edgecolor='k')\n",
    "        plt.imshow(im)\n",
    "        plt.title(\"Prediction: \" + caption_array_to_str(words[seq])[0] + \"\\nActual Caption: \" + caption_array_to_str(words[c[k]])[0], fontsize=9)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        # plt.savefig(dr + img_path.split(\"/\")[-1], bbox_inches='tight')\n",
    "        plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inception = tf.keras.applications.InceptionV3(weights='imagenet')\n",
    "inception = tf.keras.Model(inception.input, inception.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model = models[\"create_pre_inject_model\"] #change this to whatever model you want\n",
    "predict_caption(best_model, \"../input/images-for-test/test_images/\", inception, 3, \"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
